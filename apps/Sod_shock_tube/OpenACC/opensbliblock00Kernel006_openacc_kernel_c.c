//
// auto-generated by ops.py
//

#define OPS_GPU

int xdim0_opensbliblock00Kernel006;
int xdim1_opensbliblock00Kernel006;
int xdim2_opensbliblock00Kernel006;
int xdim3_opensbliblock00Kernel006;
int xdim4_opensbliblock00Kernel006;
int xdim5_opensbliblock00Kernel006;

//user function
inline 
 void opensbliblock00Kernel006(const ptr_double wk2_B0,
  const ptr_double wk1_B0,
  const ptr_double wk0_B0,
  ptr_double Residual1_B0,
  ptr_double Residual0_B0,
  ptr_double Residual2_B0)
{
   OPS_ACC(Residual0_B0, 0) = -rcinv13*(-OPS_ACC(wk0_B0, -1) + OPS_ACC(wk0_B0, 0));

   OPS_ACC(Residual1_B0, 0) = -rcinv13*(OPS_ACC(wk1_B0, 0) - OPS_ACC(wk1_B0, -1));

   OPS_ACC(Residual2_B0, 0) = -rcinv13*(OPS_ACC(wk2_B0, 0) - OPS_ACC(wk2_B0, -1));

}


void opensbliblock00Kernel006_c_wrapper(
  double *p_a0,
  double *p_a1,
  double *p_a2,
  double *p_a3,
  double *p_a4,
  double *p_a5,
  int x_size) {
  #ifdef OPS_GPU
  #pragma acc parallel deviceptr(p_a0,p_a1,p_a2,p_a3,p_a4,p_a5)
  #pragma acc loop
  #endif
  for ( int n_x=0; n_x<x_size; n_x++ ){
    const ptr_double ptr0 = {  p_a0 + n_x*1*1 };
    const ptr_double ptr1 = {  p_a1 + n_x*1*1 };
    const ptr_double ptr2 = {  p_a2 + n_x*1*1 };
    ptr_double ptr3 = {  p_a3 + n_x*1*1 };
    ptr_double ptr4 = {  p_a4 + n_x*1*1 };
    ptr_double ptr5 = {  p_a5 + n_x*1*1 };
    opensbliblock00Kernel006( ptr0,
          ptr1,ptr2,
          ptr3,ptr4,
          ptr5 );

  }
}

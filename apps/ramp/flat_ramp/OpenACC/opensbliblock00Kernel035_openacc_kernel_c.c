//
// auto-generated by ops.py
//

#define OPS_GPU

int xdim0_opensbliblock00Kernel035;
int xdim1_opensbliblock00Kernel035;

//user function
inline 
void opensbliblock00Kernel035(const ptr_double u0_B0,
  ptr_double wk7_B0,
  const int *idx)
{
    OPS_ACC(wk7_B0, 0,0) = inv_0*((idx[0] == 0) ? (
   -rc36*OPS_ACC(u0_B0, 1,0) + (rc35)*OPS_ACC(u0_B0, 0,0) -
      rc34*OPS_ACC(u0_B0, 3,0) + (rc31)*OPS_ACC(u0_B0, 4,0) + (rc33)*OPS_ACC(u0_B0, 2,0)
)
: ((idx[0] == 1) ? (

      (rc10)*OPS_ACC(u0_B0, 1,0) - rc18*OPS_ACC(u0_B0, 0,0) - rc13*OPS_ACC(u0_B0, 3,0) + (rc31)*OPS_ACC(u0_B0, -1,0)
      + (rc23)*OPS_ACC(u0_B0, 2,0)
)
: ((idx[0] == block0np0 - 1) ? (
   (rc31)*OPS_ACC(u0_B0, -4,0) +
      (rc33)*OPS_ACC(u0_B0, -2,0) + (rc35)*OPS_ACC(u0_B0, 0,0) - rc36*OPS_ACC(u0_B0, -1,0) -
      rc34*OPS_ACC(u0_B0, -3,0)
)
: ((idx[0] == block0np0 - 2) ? (
   (rc31)*OPS_ACC(u0_B0, 1,0) +
      (rc23)*OPS_ACC(u0_B0, -2,0) - rc18*OPS_ACC(u0_B0, 0,0) + (rc10)*OPS_ACC(u0_B0, -1,0) -
      rc13*OPS_ACC(u0_B0, -3,0)
)
: (
   (rc9)*OPS_ACC(u0_B0, 1,0) + (rc9)*OPS_ACC(u0_B0, -1,0) -
      rc37*OPS_ACC(u0_B0, 0,0) - rc13*OPS_ACC(u0_B0, -2,0) - rc13*OPS_ACC(u0_B0, 2,0)
)))));

}


void opensbliblock00Kernel035_c_wrapper(
  double *p_a0,
  double *p_a1,
  int *p_a2,
  int arg_idx0, int arg_idx1,
  int x_size, int y_size) {
  #ifdef OPS_GPU
  #pragma acc parallel deviceptr(p_a0,p_a1)
  #pragma acc loop
  #endif
  for ( int n_y=0; n_y<y_size; n_y++ ){
    #ifdef OPS_GPU
    #pragma acc loop
    #endif
    for ( int n_x=0; n_x<x_size; n_x++ ){
      int arg_idx[] = {arg_idx0+n_x, arg_idx1+n_y};
      const ptr_double ptr0 = {  p_a0 + n_x*1*1 + n_y*xdim0_opensbliblock00Kernel035*1*1, xdim0_opensbliblock00Kernel035};
      ptr_double ptr1 = {  p_a1 + n_x*1*1 + n_y*xdim1_opensbliblock00Kernel035*1*1, xdim1_opensbliblock00Kernel035};
      opensbliblock00Kernel035( ptr0,
          ptr1,arg_idx );

    }
  }
}
